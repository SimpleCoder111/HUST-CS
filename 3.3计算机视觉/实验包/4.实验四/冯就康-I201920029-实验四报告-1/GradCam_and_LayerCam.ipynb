{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Load the model\n",
    "model = torch.load('./pytorch/torch_alex.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image names: ['both.jpg', 'cat.jpg', 'dog.jpg']\n",
      "image paths: ['./pytorch/data4/both.jpg', './pytorch/data4/cat.jpg', './pytorch/data4/dog.jpg']\n",
      "model guess cat from both.jpg \n",
      "model guess dog from cat.jpg \n",
      "model guess dog from dog.jpg \n",
      "Target classes: [0, 1, 1]\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "analysis 0 times\n",
      "Saving GradCam Image to ./gradcam/Grad-CAM_both.jpg\n",
      "Saving LayerCAM Image to ./layercam/LayerCAM_both.jpg\n",
      "analysis 1 times\n",
      "Saving GradCam Image to ./gradcam/Grad-CAM_cat.jpg\n",
      "Saving LayerCAM Image to ./layercam/LayerCAM_cat.jpg\n",
      "analysis 2 times\n",
      "Saving GradCam Image to ./gradcam/Grad-CAM_dog.jpg\n",
      "Saving LayerCAM Image to ./layercam/LayerCAM_dog.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from pytorch_grad_cam import GradCAM, LayerCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the size your model expects\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])  # Normalize (these values are for pre-trained models on ImageNet)\n",
    "])\n",
    "\n",
    "# Define the inverse of the normalization\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "# Load image\n",
    "images_folder_path = \"./pytorch/data4/\"\n",
    "# images_folder_path = \"./image/\"\n",
    "jpg_files = glob.glob(os.path.join(images_folder_path, \"*.jpg\"))\n",
    "image_names = [os.path.basename(file) for file in jpg_files]\n",
    "\n",
    "print(f'image names: {image_names}')\n",
    "image_paths = []\n",
    "for i in range(len(image_names)):\n",
    "    image_paths.append(images_folder_path+image_names[i])\n",
    "    \n",
    "print(f'image paths: {image_paths}')\n",
    "images = [Image.open(image_path).convert('RGB') for image_path in image_paths]\n",
    "\n",
    "# Apply transformation to fit the model\n",
    "input_images = [transform_pipeline(image) for image in images]\n",
    "\n",
    "# Define target classes based on model's output\n",
    "target_classes = []\n",
    "\n",
    "# put the image into the model\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "for i, input_image in enumerate(input_images):\n",
    "    # Add a batch dimension to the image\n",
    "    input_image = input_image.unsqueeze(0)\n",
    "    # If CUDA is available, move the image to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        input_image = input_image.cuda()\n",
    "\n",
    "    # Pass the image through the model\n",
    "    output = model(input_image)\n",
    "    # print(f\"The output of model is {probabilities}\")\n",
    "    # Convert the output to probabilities using softmax\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=-1)\n",
    "    \n",
    "    # Get the predicted class by finding the class with the highest probability\n",
    "    _, predicted_class = torch.max(probabilities, dim=-1)\n",
    "\n",
    "    label = 'dog' if predicted_class == 1 else 'cat'\n",
    "    print(f'model guess {label} from {image_names[i]} ')\n",
    "    # Check if both classes have a probability higher than 0.5\n",
    "    if probabilities[0] > 0.5 and probabilities[1] > 0.5:\n",
    "        predicted_class = 2  # Both\n",
    "    target_classes.append(predicted_class.item())\n",
    "\n",
    "print(f\"Target classes: {target_classes}\")\n",
    "\n",
    "# The last Conv layer in AlexNet\n",
    "print(model.features[10])\n",
    "target_layers = [model.features[10]]\n",
    "\n",
    "for i, (input_image, target_class) in enumerate(zip(input_images, target_classes)):\n",
    "    print(f\"analysis {i} times\")\n",
    "    # Add a batch dimension to the image\n",
    "    input_image_unnorm = input_image.unsqueeze(0)\n",
    "\n",
    "    # Construct the CAM object\n",
    "    grad_cam = GradCAM(model=model, target_layers=target_layers)\n",
    "    layer_cam = LayerCAM(model=model, target_layers=target_layers)\n",
    "    # Define the target\n",
    "    targets = [ClassifierOutputTarget(target_class)]\n",
    "    # Generate the Grad-CAM and LayerCAM\n",
    "    grayscale_gradcam = grad_cam(input_tensor=input_image_unnorm, targets=targets)\n",
    "    grayscale_layercam = layer_cam(input_tensor=input_image_unnorm, targets=targets)\n",
    "    # grayscale_cam has only one image in the batch:\n",
    "    grayscale_gradcam = grayscale_gradcam[0, :]\n",
    "    grayscale_layercam = grayscale_layercam[0, :]\n",
    "    # Apply the inverse normalization to the image\n",
    "    input_image = inv_normalize(input_image)\n",
    "    # Make sure the image values are in the range [0, 1]\n",
    "    input_image = input_image.clamp(0, 1)\n",
    "    # Convert the tensor image to a numpy array\n",
    "    input_image = input_image.permute(1, 2, 0).detach().cpu().numpy()\n",
    "    \n",
    "    # Visualization \n",
    "    visualization_gradcam = show_cam_on_image(input_image, grayscale_gradcam, use_rgb=True)\n",
    "    visualization_layercam = show_cam_on_image(input_image, grayscale_layercam, use_rgb=True)\n",
    "    \n",
    "    # Save GradCam Image\n",
    "    filename = os.path.join('./gradcam/', f'Grad-CAM_{image_names[i]}')\n",
    "    filename2 = os.path.join('./layercam/', f'LayerCAM_{image_names[i]}')\n",
    "    print(f\"Saving GradCam Image to {filename}\")\n",
    "    print(f\"Saving LayerCAM Image to {filename2}\")\n",
    "    cv2.imwrite(filename, visualization_gradcam)\n",
    "    cv2.imwrite(filename2, visualization_layercam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
